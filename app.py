"""Streamlit application for visually exploring paper embeddings."""

from __future__ import annotations

import json
import tempfile
from pathlib import Path
from typing import Any, Dict, Optional

import streamlit as st

from config_utils import get_setting
from search import PaperSearcher


st.set_page_config(page_title="Paper Search Assistant", layout="wide")
st.title("ğŸ“„ Paper Search Assistant")
st.markdown(
    """
    Upload your research paper dataset, pick an embedding provider, and enter a
    short description of the papers you're looking for. The app will compute
    embeddings, rank the most relevant items, and let you download the results
    for later review.
    """
)


def _persist_uploaded_file(file) -> Optional[Path]:
    if file is None:
        return None

    suffix = Path(file.name).suffix or ".json"
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as handle:
        handle.write(file.getbuffer())
        temp_path = Path(handle.name)
    st.session_state["uploaded_name"] = file.name
    st.session_state["uploaded_suffix"] = suffix.lstrip(".")
    st.session_state["uploaded_path"] = str(temp_path)
    return temp_path


def _parse_mapping(raw_text: str) -> Dict[str, Any]:
    if not raw_text.strip():
        return {}
    try:
        mapping = json.loads(raw_text)
        if not isinstance(mapping, dict):
            raise ValueError("Mapping must be a JSON object.")
        return mapping
    except json.JSONDecodeError as exc:
        raise ValueError(f"Invalid JSON mapping: {exc}") from exc


def _load_searcher(
    data_path: Path,
    data_format: Optional[str],
    model_type: str,
    api_key: Optional[str],
    base_url: Optional[str],
    embedding_model: Optional[str],
    csv_mapping: Dict[str, Any],
):
    return PaperSearcher(
        str(data_path),
        model_type=model_type,
        api_key=api_key or None,
        base_url=base_url or None,
        data_format=data_format,
        csv_mapping=csv_mapping,
        embedding_model=embedding_model or None,
    )


st.header("1. æ•°æ®é›†")
uploaded_file = st.file_uploader(
    "ä¸Šä¼ åŒ…å«è®ºæ–‡çš„ JSONã€JSONL æˆ– CSV æ–‡ä»¶", type=["json", "jsonl", "csv"]
)

data_path: Optional[Path] = None
data_format: Optional[str] = None
if uploaded_file is not None:
    data_path = _persist_uploaded_file(uploaded_file)
elif "uploaded_path" in st.session_state:
    stored_path = Path(st.session_state["uploaded_path"])
    if stored_path.exists():
        data_path = stored_path
        st.info(
            f"ä½¿ç”¨ä¹‹å‰ä¸Šä¼ çš„æ–‡ä»¶ï¼š{st.session_state.get('uploaded_name', stored_path.name)}"
            " â€” å¦‚éœ€æ›´æ¢è¯·é‡æ–°ä¸Šä¼ ã€‚"
        )

if data_path is not None:
    data_format = Path(data_path).suffix.lstrip(".").lower()
elif "uploaded_suffix" in st.session_state:
    data_format = st.session_state["uploaded_suffix"].lower()

default_mapping_hint = (
    "{\n  \"title\": [\"æ–‡çŒ®æ ‡é¢˜\"],\n  \"abstract\": [\"æ‘˜è¦\"],\n  "
    "\"authors\": [\"ä½œè€…\"],\n  \"keywords\": [\"ä½œè€…å…³é”®å­—\"],\n  "
    "\"year\": [\"å¹´ä»½\"]\n}"
)

with st.expander("é«˜çº§ï¼šè‡ªå®šä¹‰ CSV å­—æ®µæ˜ å°„"):
    st.markdown(
        """
        å¦‚æœ CSV åˆ—åä¸é»˜è®¤çš„ Scopus æˆ–é€šç”¨å­—æ®µä¸åŒï¼Œå¯ä»¥åœ¨æ­¤ç²˜è´´ JSON
        æ ¼å¼çš„å­—æ®µæ˜ å°„ã€‚ä¾‹å¦‚ï¼š
        """
    )
    st.code(default_mapping_hint, language="json")
    mapping_text = st.text_area("è‡ªå®šä¹‰æ˜ å°„", value="", height=160)
    try:
        custom_mapping = _parse_mapping(mapping_text) if mapping_text else {}
    except ValueError as exc:
        st.error(str(exc))
        custom_mapping = {}


st.header("2. å‘é‡æ¨¡å‹è®¾ç½®")
cols = st.columns(3)
with cols[0]:
    model_type = st.selectbox(
        "åµŒå…¥æœåŠ¡æä¾›å•†",
        options=["local", "openai", "siliconflow"],
        format_func=lambda x: {
            "local": "æœ¬åœ°ï¼ˆç¦»çº¿ï¼‰",
            "openai": "OpenAI",
            "siliconflow": "ç¡…åŸºæµåŠ¨",
        }[x],
    )

with cols[1]:
    embedding_model = st.text_input(
        "åµŒå…¥æ¨¡å‹ï¼ˆå¯é€‰ï¼‰",
        placeholder={
            "local": "ä¾‹å¦‚ all-MiniLM-L6-v2",
            "openai": "ä¾‹å¦‚ text-embedding-3-large",
            "siliconflow": "ä¾‹å¦‚ BAAI/bge-large-zh-v1.5",
        }[model_type],
    )

with cols[2]:
    base_url = st.text_input(
        "è‡ªå®šä¹‰ API Base URL",
        value="https://api.siliconflow.cn/v1" if model_type == "siliconflow" else "",
        help="å¦‚ä½¿ç”¨è‡ªå»º OpenAI å…¼å®¹æœåŠ¡ï¼Œå¯åœ¨æ­¤è¦†ç›–é»˜è®¤åœ°å€ã€‚",
    )

if model_type == "openai":
    configured_key = get_setting("OPENAI_API_KEY")
elif model_type == "siliconflow":
    configured_key = get_setting("SILICONFLOW_API_KEY")
else:
    configured_key = None

api_key = st.text_input(
    "API Keyï¼ˆè‹¥é€‰æ‹©çº¿ä¸ŠæœåŠ¡ï¼‰",
    type="password",
    value=configured_key or "",
    placeholder="è¯·åœ¨ .env æˆ– config.json ä¸­é…ç½®å¯¹åº”çš„ API Key",
    key=f"api_key_{model_type}",
)

recompute = st.checkbox(
    "é‡æ–°è®¡ç®—åµŒå…¥", value=False, help="å‹¾é€‰åä¼šå¿½ç•¥ç¼“å­˜å¹¶é‡æ–°ç”ŸæˆåµŒå…¥å‘é‡ã€‚"
)


st.header("3. æ£€ç´¢é…ç½®")
query = st.text_area("è¯·è¾“å…¥æ£€ç´¢éœ€æ±‚æè¿°", placeholder="ä¾‹å¦‚ï¼šç¤¾äº¤æœºå™¨äººåœ¨é›¶å”®ç¯å¢ƒä¸­çš„åº”ç”¨")
col_search = st.columns(2)
with col_search[0]:
    top_k = st.slider("æ£€ç´¢ç»“æœæ•°é‡", min_value=1, max_value=200, value=10)
with col_search[1]:
    show_k = st.slider("ç•Œé¢å±•ç¤ºæ¡æ•°", min_value=1, max_value=50, value=10)


run_search = st.button("ğŸ” å¼€å§‹æœç´¢", type="primary")

results_state: Optional[Dict[str, Any]] = st.session_state.get("results")

if run_search:
    if data_path is None:
        st.error("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶ã€‚")
    elif not query.strip():
        st.error("è¯·è¾“å…¥æ£€ç´¢æè¿°ã€‚")
    else:
        with st.spinner("æ­£åœ¨è®¡ç®—åµŒå…¥å¹¶æ£€ç´¢ç›¸ä¼¼è®ºæ–‡..."):
            try:
                searcher = _load_searcher(
                    data_path,
                    data_format,
                    model_type,
                    api_key if api_key else None,
                    base_url or None,
                    embedding_model or None,
                    custom_mapping,
                )
                searcher.compute_embeddings(force=recompute)
                items = searcher.search(query=query, top_k=top_k)
                st.session_state["results"] = {
                    "items": items,
                    "model_name": searcher.model_name,
                    "provider": model_type,
                }
                results_state = st.session_state["results"]
            except Exception as exc:
                st.error(f"æ£€ç´¢å¤±è´¥ï¼š{exc}")
                results_state = None


if results_state and results_state.get("items"):
    st.header("ğŸ” æ£€ç´¢ç»“æœ")
    items = results_state["items"]
    for idx, item in enumerate(items[:show_k], start=1):
        paper = item["paper"]
        similarity = item["similarity"]
        title = paper.get("title", "æœªå‘½åè®ºæ–‡")
        st.markdown(f"**{idx}. [{similarity:.4f}] {title}**")

        meta_cols = st.columns(3)
        meta_cols[0].metric("å¹´ä»½", paper.get("year", "-"))
        meta_cols[1].metric("æ¥æº", paper.get("source") or paper.get("journal", "-"))
        meta_cols[2].metric("ç¼–å·", paper.get("number") or paper.get("paper_id") or paper.get("eid", "-"))

        authors = paper.get("authors")
        if isinstance(authors, list):
            authors_display = ", ".join(authors)
        else:
            authors_display = authors or "-"

        st.caption(f"ä½œè€…ï¼š{authors_display}")

        if paper.get("abstract"):
            with st.expander("æ‘˜è¦"):
                st.write(paper["abstract"])

        link = paper.get("forum_url") or paper.get("link") or paper.get("url") or paper.get("doi")
        if link:
            st.markdown(f"[æŸ¥çœ‹åŸæ–‡]({link})")

        st.divider()

    download_payload = json.dumps(
        {
            "model": results_state.get("model_name"),
            "provider": results_state.get("provider"),
            "results": items,
        },
        ensure_ascii=False,
        indent=2,
    ).encode("utf-8")
    st.download_button(
        "ğŸ’¾ ä¸‹è½½å®Œæ•´ç»“æœï¼ˆJSONï¼‰",
        download_payload,
        file_name="paper_search_results.json",
        mime="application/json",
    )

